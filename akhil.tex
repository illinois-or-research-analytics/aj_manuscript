\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{textcomp}
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
\usepackage{caption}
\usepackage{subcaption}								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{authblk}
\hypersetup{
    colorlinks=false,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    pdfpagemode=FullScreen,
}
\usepackage{float}



% \setlength{\parindent}{0pt}
%SetFonts


\begin{document}
\author{Akhil Jakatdar, Tandy Warnow, and George Chacko}
\title{Analyzing Overlapping Clustering Methods on Biological Communities }
\maketitle{}

%The ‘script is taking shape. At a high level,”Disjoint clustering is just not good enough!’. This is what the paper will be remembered for. Below that everything else we’ve thought about.
 % Equilibration across k-cores
% Top 1% experiments
% Singleton reduction
% Breadth/depth measurements
% Different classes of highly cited nodes
% Relatedness between clusters (edges and nodes)
% Case studies
% Hand waving and close out

\abstract{[\emph{Rewrite after the rest of the paper is completed.} Community detection assists the understanding of complex networks and a variety of clustering methods have been developed for this purpose. Unsurprisingly, a rich literature exists, originating from several fields, on developing and applying community detection. However, many community finding methods rely on disjoint clustering in which a node is only assigned to one community or cluster. This strict requirement limits the ability to inclusively describe communities since some nodes may reasonably be assigned to many communities. Whereas, we have previously described a scalable and modular pipeline that discovers disjoint communities, we now present a complementary overlapping community approach.  We report comparative findings from this new approach on a network of over 13 million nodes that captures recent research in the very rapidly growing field of extracellular vesicles in biology. We wanly declare relief at not having studied Zachary's Karate Club.}

\section{Introduction} The problem of identifying and characterizing research communities in the modern scientific enterprise motivates the work presented in this article. Research communities represent scientific specialization \citep{Chubin1976,Morris2009} that can span traditional disciplinary definitions \citep{Waltman2012} and evolve in response to new paradigms and incentives from funders along in a background of globalization, and industrial-scale reorganization. Consequently, we are interested in scalable methods for the identification and characterization of research communities, particularly recently emerging ones. 

One approach through which research communities can be identified is analyzing citation patterns in the scientific literature. The underlying assumption is that members of a research community are more likely to cite each other's work than the work of others. Drawing upon the rich literature from graph theory, this question can can then be framed as a community finding problem where a community is defined as a set of vertices in a graph that exhibit greater similarity to each other than vertices outside such a community. Thus, in the graph (or network) of scientific literature, citation dense areas suggest the existence of communities. Finally, the authors extracted from the community of publications are assumed to form a research community [CITE Price, Mullins, Crane, Small, Chandrasekharan, Wedell etc.]. We stress that citation density alone does not make a convincing argument for the existence of a community. However, community finding techniques for graphs are valuable in being able to efficiently search large datasets for communities that can be qualitatively examined by domain experts using complementary techniques. 

Beyond community detection, however, we are also interested in substructure (structure within communities), as it reflects roles and dynamics among members. \cite{Price1966}, in their study of the oxidative phosphorylation community, reported center–periphery substructure \citep{Breiger2014}; a small core of influential researchers and a much larger transient population. Core–periphery or center–periphery patterns have also been reported in other networks using different techniques, such as block modeling and k-core decomposition arguing for some degree of ubiquity in occurrence[CITE Rombach, Haveman, Gallagher, Sengupta, others]. 

A considerable literature exists on community finding in graphs, and a variety of community finding or clustering approaches have been used in scientometrics~\citep{Newman2006,Fortunato2009,Boyack2010,Boyack2019,Traag2019,Ahlgren2020,Chandrasekharan2021,Wedell2022}. The majority of these approaches focus on disjoint partitioning, where a vertex is only assigned to one community. We recently reported Iterative K-core Clustering (IKC) \citep{Wedell2022}, a recursive algorithmic approach based on the k-core property \citep{Giatsidis2011,malliaros2019}. We used IKC, implemented in a tunable modular pipeline to identify communities with core-periphery structure from a network of roughly 14 million articles rooted in the rapidly growing field of extracellular vesicle biology. IKC recursively extracts k-cores from a network. Subsequent steps in the pipeline include reducing cluster size and adding peripheral nodes to each core. In \cite{Wedell2022}, we acknowledged the limitations of IKC in restricting communities to disjoint partitions since some articles could reasonably be assigned to more than one community. This argument is especially relevant to articles that describe widely used methods but is conceivably also relevant to articles reporting discovery that are influential in more than community. \textcolor{blue}{Tandy please clean this paragraph up}.
 
 The limitations of disjoint clustering have been negotiated through overlapping cluster techniques [cite relevant papers]. In particular, clustering edges through line graph transformations \citep{Harary1960} has been successfully used by others \citep{Evans2009,Havemann2021} on citation data. However, the technique is not very scalable. For example, the network that we studied in \cite{Wedell2022} would grow from 14 mill nodes and 99 million edges to 99 million nodes and [insert new edge count], which presents a barrier to most clustering software.
 
 To address the disjoint cluster problem in IKC, we have developed Allowing Overlapping Clusters (AOC), a scalable meta-method that takes the output of IKC and makes multiple community assignments from a list of candidate nodes. We present results from AOC applied to the cores (centers) generated by the IKC method and discuss the effects of the technique and discovery made from it.
 
\section{Materials and Methods}

\subsection{Data} In the present study, we removed retracted and high-referencing articles from a previously generated citation network \citep{Wedell2022} inclusive of the exosome \citep{harding1983}, and more generally the extracellular vesicle, literature \citep{raposo2021}. Retracted articles were identified from a database provided by Retraction Watch and matched to the nodes in our network using digital object identifiers (DOIs). Whereas the original network consisted of 14,695,475 nodes and 99,663,372 edges, the network resultant from removing retracted and high-referencing articles comprised 13,989,436 nodes and 92,051,051 edges and is referred to, in this article, as Curated Exosome Network (CEN).

\subsection{Methods} We have previously described a clustering pipeline we refer to as Iterative K-core Clustering (IKC) in \cite{Wedell2022}, 
motivated by the graph-theoretic concept of k-cores \citep{Giatsidis2011,malliaros2019}.
This scalable and tunable method takes as input two parameters $k$ and $p$ with $k > p \geq 1$, and computes a clustering of the given network $N$ into disjoint cluster where each cluster has a ``center" component and a ``periphery".
This clustering is designed to satisfy several criteria: (1) each center of each cluster is connected,  has positive modularity, and each node in the center  is adjacent to at least $k$ other nodes in the center, and (ii) every node in the periphery of a cluster is adjacent to at least $p$ center nodes in the cluster. 
Thus, center membership requires a greater degree of connectivity to the other center nodes than periphery membership.


The IKC pipeline has three basic steps, where the second and third steps are optional.  The first step (the iterative k-core extraction algorithm) produces  disjoint clusters where each cluster has positive modularity and each node in each cluster is adjacent to at least $k$ other nodes in the cluster; these form centers of the communities.
The optional second step
breaks these clusters into smaller clusters, and the optional third step adds peripheries to the clusters. 
Note that the parameter $k$ is used to define the centers and the parameter $p$ is used to define the periphery.
If the only objective is centers of communities, then the pipeline can be run using only the first step (or optionally also with the second step if smaller communities are desired).




%recursively extracts k-cores \citep{Giatsidis2011,malliaros2019} from a network as the first stage in a tunable pipeline.

% that subsequently augments these cores with peripheral nodes while enforcing positive modularity for the core. as well as two user-defined parameters, \emph{k} and \emph{p} that describe minimum core connectivity and minimum connectivity between periphery and core respectively.

The Accommodate Overlapping Clusters (AOC) method, presented herein, builds on the first step of this pipeline (the IKC step itself).
%produces communities containing centers but not peripheries, that have positive modularity,  and where each node in each community is adjacent to at least $k$ other nodes in the community.
%AOC is run after IKC, and allows a user-specified set of nodes to be members of more than one community.
% is used to construct the set of clusters, each of which is the center of a community.  
To run AOC, the user specifies two additional parameters:  
%k$ and then applies IKC to the network using this parameter; this produces a clustering where all the clusters are connected, have positive modularity, and every node in a given cluster has at least $k$ neighbors in the cluster.  These form the ``core" (or ``centrer" of the community.  A subsequent step can be applied that enables the periphery to be added to each community.
the set of nodes that can be members of  additional clusters and the criterion for membership.  
The two criteria for membership in the core of cluster $C$ we consider are: (i) to have at least $k$ neighbors n the core of $C$ or (ii) to have at least $MCD(C)$ neighbors in the center of $C$, where $MCD(C)$ is the minimum center degree (i.e., the minimum number of center neighbors of any node within $C$). 
We also note that $k$ (the parameter for condition (i)) has been used to construct the IKC clustering; hence, for every cluster $C$,   
(i) is a weaker condition than (ii).

Thus, running   AOC on the IKC clustering produces a set of potentially overlapping clusters, each of which has positive modularity and has at least $k$ other nodes in the cluster.
These clusters form ``centers" of communities.  If desired, this clustering could then be subject to the same optional second and third steps from the IKC pipeline, which would
break up the large clusters and add periphery nodes.
In this study, we examine the properties of the clusterings produced using IKC+AOC as a function of $k$, the set of nodes to be distributed to additional clusters, and 
the criterion for inclusion in a cluster.

%user-specified candidate nodes are assigned to multiple cores extracted by the IKC method while enforcing either of the \emph{k} or \emph{m} parameters. \emph{k} describes minimal connectivity for a node in a cluster, i.e., for it to be assigned to a cluster it must have at least \emph{k} neighbours in it. \emph{m} refers to minimum cluster degree (MCD) which varies between clusters generated by IKC although they all satisfy \emph{k}. Thus \emph{k} is a network level parameter and  \emph{m} is a cluster-level that is at least as stringent as \emph{k} and typically more stringent since the majority of clusters have an MCD that is greater than \emph{k}. \textcolor{blue}{Tandy see if you'd like to state this differently.}

% \textcolor{blue}{We may need to finesse why we didn't add any peripheral nodes}.

%Add description of how AOC works...


\section{Results and Discussion}

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
	 \centering
	 \includegraphics[width=\linewidth]{fig1b.pdf} 
	 %\caption{Generic fig2 a caption} \label{fig:2a}
	 \end{subfigure}
 \hfill
	\begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig1a.pdf} 
        %\caption{Generic fig2 b caption} \label{fig:2b}
    	\end{subfigure}
\caption{Comparison of cluster sizes between disjoint (IKC)  and overlapping (AOC) clusters; cluster size selectively increases after enrichment through AOC. Clusters were generated from CEN data by IKC using values of $k$ ranging from 10 to 50. These clusters were then enriched through the AOC process enforcing either \emph{mcd} (left panel) or \emph{k} (right panel). 
The input to AOC was the  clustering produced by IKC, the value $k$ used to construct the clustering, and the set of nodes to be distributed to additional clusters was all the nodes in the IKC clusters. A natural log scale is used for both axes.}
\label{fig:fig1}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
	 \centering
	 \includegraphics[width=\linewidth]{fig2a.pdf} 
	 %\caption{Generic fig2 a caption} \label{fig:2a}
	 \end{subfigure}
 \hfill
	\begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig2b.pdf} 
        %\caption{Generic fig2 b caption} \label{fig:2b}
    	\end{subfigure}
\caption{Nodes are assigned to multiple clusters. The figure shows the count of nodes (abscissa) grouped by how many clusters a node was assigned to after AOC treatment enforcing either \emph{k} or \emph{mcd} shown as log counts or percentages of the number of nodes in non-singleton clusters (right panel). The single point noted for IKC10\_o indicates that every node is assigned to only one cluster. }
\label{fig:fig2}
\end{figure}


\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{clllllllllll}
  \hline
 no\_clusters & ikc10\_k & ikc10\_m & ikc20\_k & ikc20\_m & ikc30\_k & ikc30\_m & ikc40\_k & ikc40\_m & ikc50\_k & ikc50\_m \\ 
  \hline
1 & 246787 & 442485 & 221728 & 254435 & 85515 & 86806 & 36367 & 36463 & 2004 & 2004 \\ 
2 & 194427 & 78150 & 49195 & 20280 & 2731 & 1487 & 363 & 269 &  &  \\ 
3 & 72367 & 12518 & 4511 & 1057 &  82 &  43 &   4 &   2 &  &  \\ 
4 & 17401 & 1642 & 377 &  98 &  15 &   8 &  &  &  &  \\ 
5 & 3232 & 256 &  61 &  21 &   2 &   1 &  &  &  &  \\ 
6 & 641 &  63 &  19 &   5 &  &  &  &  &  &  \\ 
7 & 168 &  27 &   4 &  &  &  &  &  &  &  \\ 
8 &  64 &   8 &   1 &   1 &  &  &  &  &  &  \\ 
9 &  29 &   5 &   1 &  &  &  &  &  &  &  \\ 
10 &  14 &   1 &   1 &   1 &  &  &  &  &  &  \\ 
11 &   7 &   2 &  &  &  &  &  &  &  &  \\ 
12 &   6 &   3 &  &  &  &  &  &  &  &  \\ 
13 &   5 &   2 &  &  &  &  &  &  &  &  \\ 
14 &   8 &   2 &  &  &  &  &  &  &  &  \\ 
15 &   1 &  &  &  &  &  &  &  &  &  \\ 
16 &   1 &  &  &  &  &  &  &  &  &  \\ 
18 &   2 &  &  &  &  &  &  &  &  &  \\ 
19 &   2 &   1 &  &  &  &  &  &  &  &  \\ 
20 &   2 &  &  &  &  &  &  &  &  &  \\ 
24 &   1 &  &  &  &  &  &  &  &  &  \\ 
   \hline
\end{tabular}}
\caption{Table 1 caption to be added}
\label{tab:tab1}
\end{table}

% > shuffled_df
%   cluster_no   mcd modularity node_count                cluster_id
%         <int> <int>      <num>      <int>                    <char>
% 1:          1    15 0.01110796     435216  shuffled_ikc1.clustering
% 2:          1    15 0.01094716     425275 shuffled_ikc10.clustering
% 3:          1    15 0.01119657     443254  shuffled_ikc2.clustering
% 4:          1    15 0.01125269     440106  shuffled_ikc3.clustering
% 5:          1    15 0.01132720     448858  shuffled_ikc4.clustering
% 6:          1    15 0.01126005     432842  shuffled_ikc5.clustering
% 7:          1    15 0.01131381     446305  shuffled_ikc6.clustering
% 8:          1    15 0.01122132     436192  shuffled_ikc7.clustering
% 9:          1    15 0.01106562     424074  shuffled_ikc8.clustering
%10:          1    15 0.01105279     436273 shuffled_ikc9.clustering


\begin{table}[ht]
% data drawn from xtable product above using
% collate_shuffled_results.R gc 7/3/2022

\centering
\begin{tabular}{lrrrl}
  \hline
cluster\_id & cluster\_no & mcd & modularity & node\_count  \\ 
  \hline
shuffled\_CEN\_network-1 &     1 &    15 & 0.0111 & 435,216 \\
shuffled\_CEN\_network-2 &     1 &    15 & 0.0109 & 425,275 \\
shuffled\_CEN\_network-3 &     1 &    15 & 0.0112 & 443,254 \\
shuffled\_CEN\_network-4 &     1 &    15 & 0.0113 & 440,106 \\
shuffled\_CEN\_network-5 &     1 &    15 & 0.0113 & 448,858 \\
shuffled\_CEN\_network-6 &     1 &    15 & 0.0113 & 432,842 \\
shuffled\_CEN\_network-7 &     1 &    15 & 0.0113 & 446,305 \\
shuffled\_CEN\_network-8 &     1 &    15 & 0.0112 & 436,192 \\
shuffled\_CEN\_network-9 &     1 &    15 & 0.0111 & 424,074 \\
shuffled\_CEN\_network-10 &    1 &   15 & 0.0111 & 436,273 \\ 
   \hline
\end{tabular}
\caption{Comparison clustering in configuration null model. Edges of the CEN network were randomly redirected while preserving degree distribution for each node and the year of publication for citing and cited nodes. The resultant network was clustered with IKC with k=10. In the unperturbed network. 128 cores are extracted with minimum core degrees ranging from 10 to 52.  In all 10 cases of randomization, while the size and modularity of these cores vary from each other, they all exhibit a minimum core degree of 15.}
\label{tab:tab2}
\end{table}

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
	 \centering
	 \includegraphics[width=\linewidth]{ikc10_k_pw.pdf} 
	 %\caption{Generic fig2 a caption} \label{fig:2a}
	 \end{subfigure}
 \hfill
	\begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{ikc10_m_pw.pdf} 
        %\caption{Generic fig2 b caption} \label{fig:2b}
    	\end{subfigure}
\caption{Transforming IKC clusterings by AOC.  Clusters were generated from CEN data by IKC using $k=10$. These clusters were then enriched through the AOC process enforcing either \emph{k} (left panel) or \emph{mcd} (right panel). Graph edges were then reconstructed using the Jaccard Coefficient of overlap between clusters. Cluster numbers in both panels retain cluster numbers from the input IKC clustering.}
\label{fig:fig3}
\end{figure}

\begin{figure}[H]
	\centering
	 \includegraphics[width=0.7\linewidth]{marker_comps_wide.pdf} 
\caption{AOC increases marker node concentration. Notably, the proportion of 1021 marker nodes in the network, increases from 40.7 in cluster 4 (r1,c4) of IKC clustering to 93.1\% after AOC\_m to 94.6\% after AOC\_k. The proportion of markers in cluster 25 (r4,c1) is the same for IKC and AOC\_m but increases to  69.5\% under the more permissive conditions of AOC\_m. (Data are shown for the 40 clusters with non-zero marker node counts in IKC. Data for all 128 clusters are available in Supplementary Material.}
\label{fig:fig4}
\end{figure}




\subsection{Equilibration Across Cores}

\subsection{Nodes of High Degree}

\subsection{Enforcing MCD}

\subsection{Data}

\section{Conclusions}
\section{Acknowledgments etc.}

\bibliographystyle{apalike}
\bibliography{akhil.bib}

\end{document}


\textbf{ Introduce the Problem of Clustering for Bibliometrics}
\begin{itemize}
	\item Trying to identify specific communities from a larger network of publications within an overarching field
	\item Attempts to solve this problem within the lensof citation networks which means through the connections of publications based on how they cite/reference other publications within their field
	\item Focal publications can be part of many separate communities like BLAST can and should be part of many smaller communities but disjoint clustering methods leave out this possibility 
	\item Price and Beaver, Wedell et al mention the impact of a core and periphery structure, for which can we analyze the impact of overlapping clusters on the core structure
 \end{itemize}
 
 
\subsection{Center-periphery communities}

Discuss Price \& Beaver \cite{price_1966} and anything else that is related to center-periphery structure in communities.

\subsection{kmp-clustering }

The method from Wedell et al. \cite{Wedell2022} seeks to  cluster a graph into disjoint clusters, each of which 
exhibits center-periphery structure, as specified by numeric parameters $k$ and $p$ that are provided by the user.
Specifically, a cluster is said to be $k$-valid if... and $p$-valid if... and $m$-valid if...


The kmp-clustering pipeline developed in \cite{Wedell2022}  performs this clustering, based on the user provided values for $k$ and $p$, and has the following four steps: 
\begin{itemize}
	\item Step 1: IKC(N,k): producing a set of disjoint clusters, each of which is k-valid.
	\item Step 2 (optional). Divide into smaller clusters, Recursive Graclus
	\item Step 3 (optional): Augment for Periphery
	\item Step 4 (not optional): parse again, making sure to update for kmp-validity
\end{itemize}


\subsection{Overlapping clustering methods}

Here we summarize the existing methods for overlapping clusters.

\paragraph{Lambiotte and Evans}

\paragraph{Others?}

\section{Study Design}
\subsection{Overview}
We have developed a variant of the kmp-clustering method from Wedell et al. \cite{Wedell2022} that is designed to produce overlapping
clusters.
We refer to this as Overlapping kmp-clustering, or OKMP for short\footnote{This is an awful name and we should change it!}
Like kmp-clustering, the user provides values for the parameters $k$ and $p$ and the method is guaranteed to output
clusters that are $kmp$-valid.
However, unlike kmp-clustering, we allow nodes to be members of more than one cluster; as a result, the output is a clustering where
the clusters can be overlapping.

We study OKMP  in comparison to KMP-clustering (which by design produces disjoint clusters). 
We also compare OKMP to  other methods that are designed to produce overlapping clusters.
We evaluate methods on two citation networks that we construct, both developed for the Exosome biology research community.
We report empirical statistics, such as node coverage and edge coverage, and also explore cluster size.
We specifically explore the number of clusters that each publication belongs to, and evaluate the correlation between
citation count and cluster membership.
We examine pairs of overlapping clusters to understand how allowing for multiple memberships provides more insight into community
structure.



\subsection{Clustering Methods}
The main focus of this paper is the new clustering method that we have developed, Overlapping kmp-clustering, which we refer to as OKMP for short.
We also compare OKMP to other methods, which we describe below.

\subsubsection{Overlapping kmp-clustering}

\textbf{Talk about New Stage 5}

What we propose to do is add a Step 5 that will achieve overlapping clusters. More generally, the Step 5 will be able to be used with any input clustering (even if not disjoint) of a network N. And if given values for k and p, will maintain kmp-validity, if desired. Furthermore, we have a variant of this Step 5 that will maintain MCD (minimum core degree).

\textbf{Proposed greedy algorithm}

Suppose we have as input a network $N$, values for $k$ and $p$, and a clustering $\mathcal{C}$, and we want to now allow for nodes to be members in more than one cluster.  Thus we want to enhance $\mathcal{C}$ to create a new clustering, but using $\mathcal{C}$ as a starting point.
Here is a general technique:

\begin{itemize}
	\item Sort the nodes of $N$ according to some criterion (the studies mention in this paper will sort by total degree of the publication in the network)
	\item Process the nodes in order of this criterion, from best to worst, until a stopping condition applies (could be the size of the resulting clustering, or amount of time that has passed)
	\begin{itemize}
		\item Given node $v$, add $v$ to any cluster in $C \in \mathcal{C}$ where $v$ has at least $k$ neighbors (alternatively, 
		$v$ has at least $MCD(C)$ neighbors) among the core elements of $C$.
	\end{itemize}
\end{itemize}

In the current version of this algorithm, when we add a node to a cluster, we do not add the node as a core member and thus we only need to iterate over the cluster once to add all nodes



\subsubsection{Line Graph Method}

From Evans and Lambiotte, a method of overlapping clustering was proposed that involves computing the line graph equivalent of a given network and running a disjoint clustering algorithm like Leiden on the resulting line graph. 
\begin{itemize}
	\item Step 1: LG(N): produce a network where edges represent nodes, nodes represents edges
	\item Step 2 Cluster(LG(N)). Run disjoint clustering algorithm on the line graph
\end{itemize}

Talk about scalability issues of Method



\subsection{Experiments}

 
Recall that OKMP depends on the values for $k$ and $p$, but in this initial experiment we do not 
consider periphery membership, and so $p$ is irrelevant.
It also depends on which publications are allowed to be
put in more than one cluster; for our algorithm, this is mainly based on modifying $N$ where 
we order the nodes based on total degree and then only allow the top $N$ nodes to be in multiple clusters.
However, we also have a variant where we process a user-provided set of nodes, which could be all the nodes in a specific cluster, or  all the marker nodes, etc. 
Finally, OKMP depends on the rule for allowing a node to join a new cluster: do we only enforce k-validity, or do
we enforce MCD values (where MCD stands for Minimum Cluster Degree)? Here we note the MCD value of a cluster is
always (by definition) at least $k$, so that enforcing MCD is a stronger requirement, and may result in a node being added to
fewer clusters.


\textcolor{blue}{Akhil - does Stage 1 check for positive modularity? When we do Experiment 0, are we checking for positive modularity? Ditto for Experiment 1.}

\begin{itemize}
\item 
Experiment 0: Characterize step 1 of kmp-processing (i.e., we only do IKC(k)) for $k$ ranging from $10$ to $50$. These will be used
in subsequent experiments.
\item Experiment 1:  Look at OKM-clustering for different values of $k$ and for a specific set of nodes for processing. That set of nodes
will be the top $N$ nodes based on total degree or something else. For this, we only look at enforcing km-validity (not MCD).  Probably we use the top1\% of the nodes in terms of total degree for this set. 
\item Experiment 2:  Based on experiment 1, we will fix the value for $k$ (to at most two values), and now vary the set of  nodes for processing.
Here we make some discoveries about this kind of overlapping clustering.
\item Experiment 3: vary MCD vs k-m-validity to decide differences in sights.
\item Experiment 4: Take best settings so far, but break up the largest clusters (i.e., add back in the Stage 2 using Recursive Graclus).
\item Experiment 5: Allow for periphery.
\end{itemize}

In each experiment, we report:
\begin{itemize}
\item Characteristics of the set of nodes that are only in singleton clusters
\item Node coverage
\item Edge coverage
\item Cluster size distributions
\item Overlap between clusters
\end{itemize}

We show various empirical statistics of the clustering,  including the number of non-singleton clusters, the number of singleton clusters, the minimum, median and maximum cluster sizes,  node and edge coverage of the network, and node and edge coverage of the marker node subnetwork.


\section{Results \& Discussion}

\subsection{Explaining the Quantitative Metrics}
We can begin by giving a description of all metrics evaluated in the following two tables. The Number of Non-Singleton Clusters represents the number of clusters generated with at least 2 nodes in the cluster. The number of Singleton Clusters represents the number of nodes not present in any of the non-singleton clusters. The minimum cluster size represents the size of smallest non-singleton cluster generated. Similarly, the median and maximum cluster size represent the size of the median and largest non-singleton cluster generated respectively. Node Coverage is calculated by finding the percentage of nodes found in a non-singleton cluster compared to the total number of nodes in the network. Similarly, edge coverage is calculated by finding the total number of edges found in non-singleton clusters (both endpoint nodes are found in the cluster) compared to the total number of edges found in the network. We can use the same process to define marker node coverage and marker edge coverage. Marker node coverage represents the percentage of marker nodes found in non-singleton clusters compared to the total amount of marker nodes (n=95). Marker edge coverage represents the percentage of all edges that can be found in non-singleton clusters where both endpoint nodes of the edge are in the cluster (with at least one endpoint being a marker node) compared to the total edges of marker nodes. 
\newline

Results for Experiment 0 are shown in Table \ref{table:expt0}. This experiment runs the original disjoint IKC clustering method for k-values in the range of $\{10, 20, 30, 40, 50\}$. We show various empirical statistics of the clustering,  including the number of non-singleton clusters, the number of singleton clusters, the minimum, median and maximum cluster sizes,  node and edge coverage of the network, and node and edge coverage of the marker node subnetwork.

\begin{table}[h!]
\centering
\begin{small}
	\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}||p{0.95cm}| }
		\hline
		\multicolumn{11}{|r|}{Experiment 0} \\
		\hline
		Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%) & Elapsed Time (min:s) \\
		\hline
		IKC (k=10)   &  \textbf{128}    & 13454271 &   14 & 79.0 & \textbf{214877} & \textbf{3.83\%} & \textbf{11.8\% }& \textbf{89.5\% }& \textbf{8.33\% }& 26:46\\ \hline
		IKC (k=20)   &  44    & 13713538 &   60 & 246.5 & 170413 & 1.97\% & 8.24\% & 48.4\% & 6.62\% & 26:11\\ \hline
		IKC (k=30)   &  22    & 13901091 &   73 & 361.5 & 36305 & 0.63\% & 3.33\% & 42.1\% & 6.35\% & 25:22\\ \hline
		IKC (k=40)   &  6    & 13952702 &   124 & 1936.5 & 20076 & 0.26\% & 1.61\% & 41.1\% & 6.29\% & 26:01\\ \hline
		IKC (k=50)   &  1    & \textbf{13987432} &   \textbf{2004} & \textbf{2004.0} & 2004 & 0.01\% & 0.11\% & 0.00\% & 0.00\% & 24:46\\ \hline
		\hline
	\end{tabular}
	\end{small}
	\caption{Results for Experiment 0. In this experiment we run IKC on different values for $k$ between $10$ and $50$, and we report different
	empirical statistics. Note that this experiment produces disjoint clustering, and is equivalent to running Stage 1 of the $kmp$-clustering method of Wedell et al. (2022).}
		\label{table:expt0}
\end{table}

\begin{table}[h!]
\centering
\begin{small}
	\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}||p{0.95cm}| }
		\hline
		\multicolumn{11}{|c|}{Experiment 1} \\
		\hline
		Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%) & Elapsed Time (s)\\
		\hline
		IKC (k=10) w/ Step 5   &  \textbf{128}    & 13446836 &   14 & 85.0 & \textbf{275688} & \textbf{3.88\%} & \textbf{19.1\% }& \textbf{89.5\% }& \textbf{25.3\%} & 39:43\\ \hline
		IKC (k=20)  w/ Step 5 &  44    & 13702335 &   61 & 278.0 & 194798 & 2.05\% & 11.3\% & 53.7\% & 14.0\% & 29:25\\ \hline
		IKC (k=30)  w/ Step 5 &  22    & 13894563 &   73 & 388.5 & 38260 & 0.68\% & 3.80\% & 46.3\% & 7.66\% & 28:26\\ \hline
		IKC (k=40)  w/ Step 5 &  6    & 13951394 &   130 & 2299.0 & 20488 & 0.27\% & 1.70\% & 44.2\% & 6.82\% & 26:59\\ \hline
		IKC (k=50) w/ Step 5  &  1    & \textbf{13987362} &   \textbf{2074} & \textbf{2074.0} & 2074 & 0.01\% & 0.11\% & 0.00\% & 0.00\% & 25:16\\ \hline
		\hline
	\end{tabular}
	\end{small}
	\caption{Results for Experiment 1. This is the result of running IKC for different values of $k$ and then allowing some nodes to be members in multiple clusters. The set of nodes that are allowed to belong to multiple clusters is the top 1\% of nodes, by total degree. These are placed independently of each other, and so order does not matter.  Membership in a new cluster requires that the added node be adjacent to at least $k$ other nodes in the IKC cluster (thus, newly added nodes do not vote on membership for other new nodes)}
	\label{table:expt1}
\end{table}


\begin{table}[h!]
	\centering
	\begin{small}
		\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}| }
			\hline
			\multicolumn{10}{|c|}{Experiment 2 Indegree} \\
			\hline
			Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%)\\
			\hline
			IKC (k=20)  w/ Step 5 In-degree $1\%$ &  44    & \cellcolor{blue!20} 13702262 &   61 & \cellcolor{red!20} 280.5 & \cellcolor{blue!20}192690 & 2.05\% & \cellcolor{blue!20}11.0\% & \cellcolor{blue!20}52.6\% & \cellcolor{blue!20}13.6\% \\ \hline

			IKC (k=40)  w/ Step 5 In-degree $1\%$ &  6    & \cellcolor{red!20}13951603 &   \cellcolor{red!20}131 & \cellcolor{red!20}2235.5 & \cellcolor{blue!20}20462 & 0.27\% & \cellcolor{blue!20}1.69\% & \cellcolor{blue!20}42.1\% & \cellcolor{blue!20}6.52\% \\ \hline
			
			IKC (k=20)  w/ Step 5 In-degree $5\%$&  44    & \cellcolor{blue!20}13621558 &   61 & \cellcolor{red!20}450.0 & \cellcolor{red!20}229928 & \cellcolor{red!20}2.63\% & \cellcolor{red!20}14.5\% & \cellcolor{red!20}72.6\% & \cellcolor{red!20}17.7\% \\ \hline
			
			IKC (k=40)  w/ Step 5 In-degree $5\%$ &  6    & \cellcolor{blue!20}13949455 &   \cellcolor{red!20}139 & \cellcolor{red!20}2645.0 & \cellcolor{red!20}21002 & \cellcolor{red!20}0.29\% & \cellcolor{red!20}1.80\% & \cellcolor{red!20}47.4\% & \cellcolor{red!20}7.29\% \\ \hline

			 \hline
			\hline
					\end{tabular}
		\end{small}
	\caption{Results for Experiment 2. We now decide to fix k=20, 40 and vary the input candidate set. We take a look at the following variations:  changing the candidate criterion to in-degree instead of total degree and looking at the top $1\%$ of nodes and top $5\%$ of nodes respectively. }
	\label{table:expt2indegree}
\end{table}

\begin{table}[h!]
	\centering
	\begin{small}
		\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}| }
			\hline
			\multicolumn{10}{|c|}{Experiment 2 Total Degree} \\
			\hline
			Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%)\\
			\hline
			IKC (k=20)  w/ Step 5 Total Degree $5\%$&  44    & \cellcolor{blue!20}13603978 &   \cellcolor{red!20}62 & \cellcolor{red!20}480.5 & \cellcolor{red!20}232822 &\cellcolor{red!20}2.76\% & \cellcolor{red!20}15.7\% & \cellcolor{red!20}77.9\% & \cellcolor{red!20}21.7\%  \\ \hline
			
			IKC (k=40)  w/ Step 5 Total Degree $5\%$ &  6    & \cellcolor{blue!20}13948073 &   \cellcolor{red!20}144 & \cellcolor{red!20}2909.0 & \cellcolor{red!20}21345 & \cellcolor{red!20}0.30\% & \cellcolor{red!20}1.87\% & \cellcolor{red!20}48.4\% & \cellcolor{red!20}8.10\% \\
			\hline
			\hline
		\end{tabular}
	\end{small}
	\caption{Results for Experiment 2. We now decide to fix k=20, 40 and vary the input candidate set. We take a look at the following variations:  changing the candidate criterion to the  top $5\%$ of nodes by total degree.}
	\label{table:expt2totaldegree}
\end{table}

\begin{table}[h!]
	\centering
	\begin{small}
		\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}| }
			\hline
			\multicolumn{10}{|c|}{Experiment 2 Random} \\
			\hline
			Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%)\\
			\hline
			IKC (k=20)  w/ Step 5 Random &  44    & \cellcolor{red!20}13711657 &   \cellcolor{blue!20}60 & \cellcolor{blue!20}250.0 & \cellcolor{blue!20}171448 & \cellcolor{blue!20}2.00\% & \cellcolor{blue!20}8.32\% & \cellcolor{blue!20}49.5\% & \cellcolor{blue!20}6.72\% \\ \hline
			
			IKC (k=40)  w/ Step 5 Random  &  6    & \cellcolor{red!20}13952652 &   \cellcolor{blue!20}124 & \cellcolor{blue!20}1946.0 & \cellcolor{blue!20}20090 & \cellcolor{blue!20}0.26\% & \cellcolor{blue!20}1.61\% & \cellcolor{blue!20}41.1\% & \cellcolor{blue!20}6.31\% \\ \hline
			\hline
		\end{tabular}
	\end{small}
	\caption{Results for Experiment 2. We now decide to fix k=20, 40 and vary the input candidate set. We take a look at the following variations:  changing the candidate criterion to a random $1\%$ of nodes from the network. }
	\label{table:expt2random}
\end{table}

\begin{table}[h!]
	\centering
	\begin{small}
		\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}| }
			\hline
			\multicolumn{10}{|c|}{Experiment 2 95th Percentile} \\
			\hline
			Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%)\\
			\hline
			IKC (k=20)  w/ Step 5 Total Degree 95 Percentile &  44    & \cellcolor{blue!20}13684128 &   61 & \cellcolor{blue!20}268.5 & \cellcolor{blue!20}180166 & \cellcolor{red!20}2.18\% & \cellcolor{blue!20}9.04\% & \cellcolor{blue!20}49.5\% & \cellcolor{blue!20}6.92\% \\ \hline
			
			IKC (k=40)  w/ Step 5 Total Degree 95 Percentile  &  6    & \cellcolor{red!20}13952552 &   \cellcolor{blue!20}124 & \cellcolor{blue!20}1940.0 & \cellcolor{blue!20}20170 & \cellcolor{blue!20}0.26\% & \cellcolor{blue!20}1.62\% & \cellcolor{blue!20}41.1\% & \cellcolor{blue!20}6.29\% \\ \hline
			\hline
			IKC (k=20)  w/ Step 5 Indegree 95 Percentile &  44    & \cellcolor{blue!20}13700075 &   \cellcolor{blue!20}60 & \cellcolor{blue!20}253.0 & \cellcolor{blue!20}176775 & \cellcolor{red!20}2.07\% & \cellcolor{blue!20}8.64\% & \cellcolor{blue!20}49.5\% & \cellcolor{blue!20}7.02\% \\ \hline
			
			IKC (k=40)  w/ Step 5 Indegree 95 Percentile  &  6    &\cellcolor{red!20}13952523 &   \cellcolor{blue!20}125 & \cellcolor{blue!20}1968.0 & \cellcolor{blue!20}20128 & \cellcolor{blue!20}0.26\% & \cellcolor{blue!20}1.62\% &\cellcolor{blue!20}41.1\% & \cellcolor{blue!20}6.34\% \\ \hline
			\hline
		\end{tabular}
	\end{small}
	\caption{Results for Experiment 2. We now decide to fix k=20, 40 and vary the input candidate set. We take a look at the following variations:  changing the candidate criterion to the 95th percentile (94.5-95.5) of nodes by either in-degree or total degree. }
	\label{table:expt2}
\end{table}
			 
\begin{table}[h!]
	\centering
	\begin{small}
		\begin{tabular}{ |p{0.95cm}||p{1.25cm}|p{1.25cm}||p{1.20cm}|p{1.20cm}|p{1.20cm}||p{1.25cm}|p{1.25cm}|| p{1.25cm}|p{1.25cm}| }
			\hline
			\multicolumn{10}{|c|}{Experiment 2 Seed} \\
			\hline
			Method & Number of Non-Singleton Clusters & Number of Singleton Clusters & Minimum Cluster Size &  Median Cluster Size & Maximum Cluster Size & Node Coverage (\%)& Edge Coverage  (\%)& Marker Node Coverage  (\%)& Marker Edge Coverage  (\%)\\
			\hline
			IKC (k=20)  w/ Step 5 Seed &  44    & \cellcolor{blue!20}13526555 &  \cellcolor{red!20} 62 & \cellcolor{red!20}495.0 &\cellcolor{red!20} 270561 & \cellcolor{red!20}3.31\% & \cellcolor{red!20}18.1\% & \cellcolor{red!20}77.9\% & \cellcolor{red!20}22.6\% \\ \hline
			
			IKC (k=40)  w/ Step 5 Seed  &  6    & \cellcolor{blue!20}13948032 &   \cellcolor{red!20}144 & \cellcolor{red!20}2910.5 & \cellcolor{red!20}21371 & \cellcolor{red!20}0.30\% &\cellcolor{red!20}1.87\% & \cellcolor{red!20}48.4\% & \cellcolor{red!20}8.10\% \\  \hline
			\hline
		\end{tabular}
	\end{small}
	\caption{Results for Experiment 2 Seed. We now decide to fix k = 20, 40 and vary the input candidate set. We take a look at the following variations:  changing the candidate criterion to the seed set and the marker nodes.}
	\label{table:expt2seed}
\end{table}

	
Experiment 2:
\begin{itemize}
	\item X is a random set of nodes found in clusters \textbf{done}
	\item X is set of publications with top 5$\%$ in terms of degree \textbf{done}
	\item X is the same number of publications at the 95th percentile (94.5-95.5%)
	\item X is the set of publications with top 1$\%$in terms of in-degree \textbf{done}
	\item X is the set of publications with top 5$\%$ in terms of in-degree  \textbf{done}
	\item X is the set of publications between 94.5-95.5$\%$ in terms of in-degree
	\item X is some set of marker nodes. (ALL marker nodes)
		All 1200 from Wedell et al. 2022
		The more recent set of 94 marker nodes
		The set of S nodes
\end{itemize}


\subsection{Observations}

When looking at Experiment 0, which looks at disjoint IKC km-valid clusterings, we notice the trend that as we increase k-value, we restrict our clusters lesser nodes from the network, albeit potentially more informative and connected ones. The number of non-singleton nodes decreases as k increases, while the median and minimum cluster size increase and the maximum cluster size decreases. As the selectivity of the clustering algorithm increases, we notice that the distribution of cluster sizes tends to the median. Node coverage and edge coverage also decrease as the selectivity of the clustering algorithm increases as expected in the inverse relationship between selectivity and coverage. Interestingly, we notice that the marker node coverage is greater than node coverage (which represents all nodes in the graph), while marker edge coverage is actually less that the average node for k=10, k=20 byt bit for large values of k up until k=50. We can attribute this to the fact that increasing selectivity values papers with higher total degrees which in turn tend to be papers with greater significance in their field. Thus marker node abnd edge coverage being proportionally higher for more selective values of k supports this idea. \newline\newline

We can then look at Experiment 1, which looks at the OKMP valid clustering based on the same original disjoint IKC km-valid clusterings from Experiment 0. Given that our algorithm only adds candidate nodes to existing clusters from the input disjoint clusterings, the number of non-singleton clusters stays the same. However, we notice the general trends of increases in minimum, median and maximum cluster sizes, and decreases in singleton clusters. These trends continue to show in node and edge coverage which both increase for all k-values. Given that this stage takes the set of the top $1\%$ of nodes by total degree to be considered when adding to existing clusters, we can notice that the maximum increase of node coverage is bounded at $1\%$. We also notice that unlike Experiment 0, the marker edge coverage exceeds the edge coverage for all k-values (except k=50), which gives evidence that points to OKMP valuing these marker nodes in its clustering coverage much greater than the disjoint clustering method did. \newline\newline

\subsubsection{Experiment 2 Observations}

Observations:
\begin{itemize}
	\item Indegree in general gives lower edge coverage than total degree for both $1\%$ and $5\%$
	\item Node coverage marginally increases for k=20 indegree however
	\item k = 20 delta from Experiment 0 to Experiment 1 node coverage: +0.08, edge coverage + 3.06, from Experiment 1 to Experiment 2 node coverage: +0.71, edge coverage: + 4.40
	\item as we increase threshold to 5 percent, node coverage increases at higher rates than edge coverage
	\item 95th percentile of nodes sees greater node coverage  than top 1 percent for k=20
\end{itemize}



\subsection{Results of Overlapping KMP-clustering}
Note that OKMP (Overlapping kmp-clustering) depends only on the values for $k$ and $p$, and also on the stopping rule (i.e., which nodes we process and allow to be in multiple clusters). In this first experiment, we explore the impact of changing the value of $k$ and the set of nodes to process.
We also then consider the impact of allowing for periphery membership.



\subsection{Comparison between Overlapping kmp- and Disjoint kmp-clustering}

\subsection{Comparison between Overlapping kmp-clustering and Line Graph Clustering}



\subsection{Marker Node Analysis}

\textbf{Question:} Can we run an MDS analysis similar to what was done in Wedell et al?


Plotting modularity increases and decreases, differences in size of cluster

