\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

%SetFonts

%SetFonts


\title{QSS-2022-0063: Response to First Review}
\author{George Chacko}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
\section*{}

We thank the reviewers for the professional courtesy of evaluating our manuscript. We thank the Editor for the opportunity to respond to the comments 
offered by the two reviewers and for inviting us to revise this manuscript. We have attempted to respond to all the points raised by the reviewers.

Please note that another author has been added to this work. Mr. Baqiao Liu is a graduate student who has conducted verification and follow-up studies, and 
has refactored our Python implementation of the AOC algorithm. 

We regretfully report that, after submitting this manuscript to QSS on Aug 5, 2022 we discovered a coding error while conducting a code review. The error was discovered 
on \underline{Aug 17, 2022},  and we communicated this to the Editor and QSS journal on \underline{Aug 18, 2022}. 

The error concerned a ``for loop" that was used to calculate modularity and we have since corrected our code. All four authors are aware of this problem and 
concur on remediating it. Our preprint on arXiv was updated on Aug 24 and 26 to reflect corrections.  The revised manuscript contains corrected data.

The impact of the error is seen in 2 of 128 clusters  that we describe in our manuscript and amounts to less than a 10\% change in size for these two.
 
Specifically, clusters \#3 and \#4 after AOC\_k treatment of IKC10 clusters were previously of size 265,681 and 316,185 nodes respectively. After running the corrected code, these
clusters reduce to 242,857 and 291,154 nodes respectively and the corrected clusters exhibit 8.6\% and 7.9\% reductions in size. These two clusters are of interest because 
they are  enriched in marker nodes. After running the corrected script, marker node concentration reduced as follows. 

\begin{itemize}
\item Cluster 3: Previously contained 71.8 \% of 1021 markers and now contains 60.5\% of these markers.
\item Cluster 4: Previously contained 94.6 \% of 1021 markers and now contains 91.3 \% of these markers. These differences do not change our results qualitatively, and our final conclusions remain the same. 
\end{itemize}


\subsection*{Reviewer 1} \emph{Interesting and well written paper. You should shortly discuss your data model (direct citations?). In contrast to the definition, you measure modularity of single communities. An expert understands that this is meaningful but a newcomer should get a sentence of explanation.  You could mention the recent paper by Havemann et al. about "Communities as Well Separated Subgraphs With Cohesive Cores: Identification of Core-Periphery Structures in Link Communities". You refer to Suppl. Mat. but I have not found any. On page 6 in line 36: contains -> contain. Please, check the first sentence of 3.5 (page 16).}

\vspace{4 mm}
Thank you. We have added a discussion of our data model. We have also clarified why we measure modularity of single clusters as opposed to globally maximizing modularity. We have added the recommended 
Havemann reference to supplement our citation of his other paper. ``Topics as clusters of citation links to highly cited sources: The case of research on international relations." The approach is different from 
ours but the work is relevant.

The Supplementary Material link was lost during manuscript preparation. Our apologies for this oversight. It is now available via browser. We have also enclosed a copy. We have corrected the the two typos identified
above.

\clearpage

\subsection*{Reviewer 2} \emph{The authors propose a new algorithm (AOC) to assign nodes in a network to previously obtained clusters (in particular from the previously proposed IKC approach). By the use of AOC we get overlapping clusters. Both IKC and AOC are based on the idea that each community is centralized around a set of core nodes in the network. IKC aims to identify such cores, while AOC uses a similar logic to assign nodes to all cores for which the nodes fulfill some inclusion criteria. I find this logic reasonable and well presented by the authors. The background is clearly formulated, and the methods are comprehensively described. However, I have one major concern about the paper. The results presented does not seem very reasonable and I doubt that the obtained clustering can be used for the intended purpose (identifying and characterizing research communities). I think that the authors need to show that this is the case.} 

\emph{The background is clearly formulated, and the methods are comprehensively described. However, I have one major concern about the paper. The results presented does not seem very reasonable and I doubt that the obtained clustering can be used for the intended purpose (identifying and characterizing research communities). I think that the authors need to show that this is the case.}

\emph{From a set of about 14 million publications, only 128 cores are identified (using k=10). It is stated that the cores “range in size from 14 to 214,877, with a median core size of 79”. Around 40\% of the assigned nodes are in the same core. I find it likely that such distribution will make it difficult to identify and characterize research communities. If there are clear reasons for this distribution (e.g. if the distribution is reasonable given some knowledge of the field) the authors should discuss these reasons. The marker nodes are concentrated into 3 clusters; however, we do not get to know the size or scope of these clusters.}

\emph{I do not understand the logic for using the exosome data set. This was constructed by a search for “exosome”, retrieving all publications from the search results and then adding all referenced work. Such a methodology creates a network where the publications retrieved from the search are likely to have many connections (all their references are included) while a long tail of records will have very few relations (publications that are peripheral to the field and not having their references included). Such properties are likely to have large impact on the clustering. Is there a particular reason to use a network with these characteristics for this study?}

\emph{The authors have not addressed a couple of important properties of citation networks. Dynamics being one of the properties and the other being the different citation density in different fields. No normalization of citation relations has been performed (full counts are used). This may be one of the reasons for the very large cluster created by the algorithm. Publications gain citations over time. This means that they are more likely to be assigned to cores if they are older. This is perhaps reasonable, given that they have had more impact on the community. However, they are also more likely to be assigned to several cores. For the purpose of identifying research communities, I find this property to be problematic. I also find the full counts approach problematic, for example given the above discussed properties of the exosome network.}

\emph{I lack a clear presentation of the characteristics of the obtained cluster solution (after each step). For example, the distribution of cluster sizes. I think the authors should avoid using natural log scale, because it makes the interpretation more difficult. I also would like to see some statistic.}

\vspace{4 mm}

The review raises a number of thought-provoking points. 

\end{document}  


